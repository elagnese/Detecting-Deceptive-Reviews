{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "VERSION 1: Full Pipeline with Baseline, BERT+MLP, Hybrid XGBoost, SHAP, and Error Analysis"
      ],
      "metadata": {
        "id": "z94olNB2Xgck"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usTjE-8dKWtt"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# [CELL 1] INSTALLATION & IMPORTS\n",
        "# ==========================================\n",
        "!pip install pandas numpy torch xgboost transformers scikit-learn matplotlib shap lime tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import AdamW\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc, confusion_matrix\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Setup Device\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Running on {DEVICE}\")\n",
        "shap.initjs()\n",
        "\n",
        "# ==========================================\n",
        "# [CELL 2] PHASE 1: DATA PREP & FEATURE ENGINEERING\n",
        "# ==========================================\n",
        "print(\"\\n--- PHASE 1: Data Preparation ---\")\n",
        "\n",
        "# 1. Load Data\n",
        "try:\n",
        "    df = pd.read_csv('fake reviews dataset.csv')\n",
        "    print(f\"Data Loaded: {len(df)} rows\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'fake reviews dataset.csv' not found. Please upload it.\")\n",
        "\n",
        "# 2. Target Creation\n",
        "df['target'] = df['label'].apply(lambda x: 1 if x == 'CG' else 0)\n",
        "\n",
        "# 3. Feature Engineering\n",
        "df['text_len'] = df['text_'].apply(len)\n",
        "df['word_count'] = df['text_'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "# 4. Preprocessing Metadata\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), ['category']),\n",
        "        ('num', StandardScaler(), ['rating', 'text_len', 'word_count'])\n",
        "    ],\n",
        "    remainder='drop',\n",
        "    verbose_feature_names_out=False\n",
        ")\n",
        "\n",
        "structured_features = preprocessor.fit_transform(df[['category', 'rating', 'text_len', 'word_count']])\n",
        "feature_names = preprocessor.get_feature_names_out()\n",
        "# Rename to avoid collisions\n",
        "feature_names = [f\"scaled_{name}\" if name in ['rating', 'text_len', 'word_count'] else name for name in feature_names]\n",
        "\n",
        "structured_df = pd.DataFrame(structured_features, columns=feature_names)\n",
        "df_final = pd.concat([df[['text_', 'target']], structured_df], axis=1)\n",
        "\n",
        "print(\"Feature Engineering Complete.\")\n",
        "\n",
        "# ==========================================\n",
        "# [CELL 3] PHASE 2: BASELINE MODEL\n",
        "# ==========================================\n",
        "print(\"\\n--- PHASE 2: Baseline (TF-IDF + LR) ---\")\n",
        "\n",
        "X_base_train, X_base_test, y_base_train, y_base_test = train_test_split(\n",
        "    df['text_'], df['target'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf.fit_transform(X_base_train)\n",
        "X_test_tfidf = tfidf.transform(X_base_test)\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train_tfidf, y_base_train)\n",
        "print(f\"Baseline Accuracy: {lr.score(X_test_tfidf, y_base_test):.4f}\")\n",
        "\n",
        "# ==========================================\n",
        "# [CELL 4] PHASE 3: BERT + MLP (Deep Learning)\n",
        "# ==========================================\n",
        "print(\"\\n--- PHASE 3: BERT + MLP (Full Fine-Tuning) ---\")\n",
        "\n",
        "# CONFIG FOR BERT MLP\n",
        "TRAIN_BERT_MLP = True  # <--- Set to False to skip this slow part\n",
        "EPOCHS = 2\n",
        "BATCH_SIZE = 16\n",
        "LR = 2e-5\n",
        "\n",
        "if TRAIN_BERT_MLP:\n",
        "    # 1. Dataset Class\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    class ReviewDataset(Dataset):\n",
        "        def __init__(self, df, tokenizer, max_len=128):\n",
        "            self.texts = df['text_'].to_numpy()\n",
        "            self.targets = df['target'].to_numpy()\n",
        "            self.meta = df[feature_names].to_numpy().astype(np.float32)\n",
        "            self.tokenizer = tokenizer\n",
        "            self.max_len = max_len\n",
        "        def __len__(self):\n",
        "            return len(self.texts)\n",
        "        def __getitem__(self, idx):\n",
        "            encoding = self.tokenizer.encode_plus(\n",
        "                str(self.texts[idx]),\n",
        "                add_special_tokens=True,\n",
        "                max_length=self.max_len,\n",
        "                return_token_type_ids=False,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_attention_mask=True,\n",
        "                return_tensors='pt',\n",
        "            )\n",
        "            return {\n",
        "                'input_ids': encoding['input_ids'].flatten(),\n",
        "                'attention_mask': encoding['attention_mask'].flatten(),\n",
        "                'metadata': torch.tensor(self.meta[idx]),\n",
        "                'targets': torch.tensor(self.targets[idx], dtype=torch.long)\n",
        "            }\n",
        "\n",
        "    # 2. Split & Loaders\n",
        "    df_train, df_test = train_test_split(df_final, test_size=0.2, random_state=42)\n",
        "    train_ds = ReviewDataset(df_train, tokenizer)\n",
        "    test_ds = ReviewDataset(df_test, tokenizer)\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "    # 3. Model Definition\n",
        "    class HybridBertMLP(nn.Module):\n",
        "        def __init__(self, n_meta):\n",
        "            super(HybridBertMLP, self).__init__()\n",
        "            self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "            fused_dim = 768 + n_meta\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(fused_dim, 256),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.3),\n",
        "                nn.Linear(256, 2)\n",
        "            )\n",
        "        def forward(self, input_ids, attention_mask, metadata):\n",
        "            output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            cls_emb = output.last_hidden_state[:, 0, :]\n",
        "            fused = torch.cat((cls_emb, metadata), dim=1)\n",
        "            return self.classifier(fused)\n",
        "\n",
        "    model_mlp = HybridBertMLP(n_meta=len(feature_names)).to(DEVICE)\n",
        "    optimizer = AdamW(model_mlp.parameters(), lr=LR)\n",
        "    loss_fn = nn.CrossEntropyLoss().to(DEVICE)\n",
        "\n",
        "    # 4. Training Loop\n",
        "    print(\"Starting BERT+MLP Training (This may take time)...\")\n",
        "    for epoch in range(EPOCHS):\n",
        "        model_mlp.train()\n",
        "        total_loss = 0\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "            ids = batch['input_ids'].to(DEVICE)\n",
        "            mask = batch['attention_mask'].to(DEVICE)\n",
        "            meta = batch['metadata'].to(DEVICE)\n",
        "            targets = batch['targets'].to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model_mlp(ids, mask, meta)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1} Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # 5. Evaluation for BERT+MLP\n",
        "    model_mlp.eval()\n",
        "    mlp_preds, mlp_true = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            ids = batch['input_ids'].to(DEVICE)\n",
        "            mask = batch['attention_mask'].to(DEVICE)\n",
        "            meta = batch['metadata'].to(DEVICE)\n",
        "            targets = batch['targets'].to(DEVICE)\n",
        "            outputs = model_mlp(ids, mask, meta)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            mlp_preds.extend(preds.cpu().numpy())\n",
        "            mlp_true.extend(targets.cpu().numpy())\n",
        "\n",
        "    print(f\"\\nBERT+MLP Accuracy: {accuracy_score(mlp_true, mlp_preds):.4f}\")\n",
        "else:\n",
        "    print(\"Skipping BERT+MLP Training (Flag is False)\")\n",
        "\n",
        "# ==========================================\n",
        "# [CELL 5] PHASE 4: BERT + XGBOOST (Hybrid)\n",
        "# ==========================================\n",
        "print(\"\\n--- PHASE 4: Optimized Hybrid (BERT + XGBoost) ---\")\n",
        "\n",
        "# 1. Extract Embeddings (Frozen BERT)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased').to(DEVICE)\n",
        "bert_model.eval()\n",
        "\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    embeddings = []\n",
        "    print(\"Extracting BERT features...\")\n",
        "    for i in tqdm(range(0, len(texts), batch_size)):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        encoded = tokenizer(batch_texts, padding=True, truncation=True, max_length=128, return_tensors='pt').to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            out = bert_model(**encoded)\n",
        "            embeddings.append(out.last_hidden_state[:, 0, :].cpu().numpy())\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "# Check inputs are strings\n",
        "text_data = df_final['text_'].astype(str).tolist()\n",
        "X_text_emb = get_embeddings(text_data)\n",
        "\n",
        "# 2. Fuse & Split\n",
        "X_hybrid = np.hstack((X_text_emb, structured_features))\n",
        "y_hybrid = df_final['target'].values\n",
        "\n",
        "# FIX: Unpack 6 values here (Train X, Test X, Train y, Test y, Train Text, Test Text)\n",
        "X_train, X_test, y_train, y_test, text_train, text_test = train_test_split(\n",
        "    X_hybrid, y_hybrid, df_final['text_'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Train XGBoost\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.05, n_jobs=-1)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "print(\"XGBoost Hybrid Model Trained.\")\n",
        "\n",
        "# ==========================================\n",
        "# [CELL 6] EVALUATION\n",
        "# ==========================================\n",
        "print(\"\\n--- PHASE 5: Evaluation (Hybrid XGBoost) ---\")\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "print(f\"Hybrid Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Original', 'Fake']))\n",
        "\n",
        "# Plot ROC\n",
        "y_probs = xgb_model.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {auc(fpr, tpr):.2f}\")\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.title(\"ROC Curve (Hybrid XGBoost)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ==========================================\n",
        "# [CELL 7] EXPLAINABILITY\n",
        "# ==========================================\n",
        "print(\"\\n--- PHASE 6: Explainability ---\")\n",
        "# Global Importance (SHAP)\n",
        "bert_names = [f\"bert_{i}\" for i in range(768)]\n",
        "all_names = bert_names + list(feature_names)\n",
        "xgb_model.get_booster().feature_names = all_names\n",
        "\n",
        "explainer = shap.TreeExplainer(xgb_model)\n",
        "shap_vals = explainer.shap_values(X_test[:100])\n",
        "shap.summary_plot(shap_vals, X_test[:100], feature_names=all_names, plot_type=\"bar\")\n",
        "\n",
        "# ==========================================\n",
        "# [CELL 8] ERROR ANALYSIS\n",
        "# ==========================================\n",
        "print(\"\\n--- PHASE 7: Error Analysis ---\")\n",
        "errors = pd.DataFrame({'text': text_test.values, 'true': y_test, 'pred': y_pred, 'prob': y_probs})\n",
        "fp = errors[(errors['true']==0) & (errors['pred']==1)]\n",
        "print(f\"False Positives: {len(fp)}\")\n",
        "if not fp.empty:\n",
        "    top_fp = fp.sort_values('prob', ascending=False).iloc[0]\n",
        "    print(f\"Top False Positive (Real flagged as Fake): \\n{top_fp['text'][:200]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VERSION 2: Optimized Hybrid Model + LIME & SHAP Explainability"
      ],
      "metadata": {
        "id": "4Rcsm85RWSWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# [CELL 1] INSTALLATION & IMPORTS\n",
        "# ==========================================\n",
        "!pip install pandas numpy torch xgboost transformers scikit-learn matplotlib shap lime tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "import lime\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Setup Device\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Running on {DEVICE}\")\n",
        "shap.initjs()\n",
        "\n",
        "# ==========================================\n",
        "# [CELL 2] PHASE 1: DATA PREP & FEATURE ENGINEERING\n",
        "# ==========================================\n",
        "print(\"\\n--- PHASE 1: Data Preparation ---\")\n",
        "try:\n",
        "    df = pd.read_csv('fake reviews dataset.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'fake reviews dataset.csv' not found. Please upload it.\")\n",
        "\n",
        "df['target'] = df['label'].apply(lambda x: 1 if x == 'CG' else 0)\n",
        "df['text_len'] = df['text_'].apply(len)\n",
        "df['word_count'] = df['text_'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), ['category']),\n",
        "        ('num', StandardScaler(), ['rating', 'text_len', 'word_count'])\n",
        "    ],\n",
        "    remainder='drop',\n",
        "    verbose_feature_names_out=False\n",
        ")\n",
        "\n",
        "structured_features = preprocessor.fit_transform(df[['category', 'rating', 'text_len', 'word_count']])\n",
        "feature_names = preprocessor.get_feature_names_out()\n",
        "feature_names = [f\"scaled_{name}\" if name in ['rating', 'text_len', 'word_count'] else name for name in feature_names]\n",
        "\n",
        "structured_df = pd.DataFrame(structured_features, columns=feature_names)\n",
        "df_final = pd.concat([df[['text_', 'target']], structured_df], axis=1)\n",
        "print(\"Feature Engineering Complete.\")\n",
        "\n",
        "# ==========================================\n",
        "# [CELL 3] PHASE 2: BASELINE\n",
        "# ==========================================\n",
        "# (Skipping execution for brevity, but code is same as before)\n",
        "print(\"\\n--- PHASE 2: Baseline Skipped for Speed ---\")\n",
        "\n",
        "# ==========================================\n",
        "# [CELL 4] PHASE 3: BERT + MLP (Definition)\n",
        "# ==========================================\n",
        "# (Deep Learning Class Definition - Same as before)\n",
        "class HybridBertMLP(nn.Module):\n",
        "    def __init__(self, n_metadata_features, n_classes=2):\n",
        "        super(HybridBertMLP, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        total_fused_dim = 768 + n_metadata_features\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(total_fused_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, n_classes)\n",
        "        )\n",
        "    def forward(self, input_ids, attention_mask, metadata_features):\n",
        "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_embedding = bert_output.last_hidden_state[:, 0, :]\n",
        "        fused_vector = torch.cat((cls_embedding, metadata_features), dim=1)\n",
        "        return self.classifier(fused_vector)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# [CELL 5] PHASE 4: OPTIMIZED HYBRID (BERT + XGBOOST)\n",
        "# ==========================================\n",
        "print(\"\\n--- PHASE 4: Optimized Hybrid (BERT + XGBoost) ---\")\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased').to(DEVICE)\n",
        "bert_model.eval()\n",
        "\n",
        "def extract_bert_embeddings(texts, batch_size=32):\n",
        "    embeddings = []\n",
        "    # Only show progress bar if batch is large\n",
        "    disable_tqdm = len(texts) < 50\n",
        "    iterator = range(0, len(texts), batch_size)\n",
        "    if not disable_tqdm:\n",
        "         iterator = tqdm(iterator, desc=\"BERT Extraction\")\n",
        "\n",
        "    for i in iterator:\n",
        "        batch_texts = texts[i : i + batch_size]\n",
        "        encoded = tokenizer(\n",
        "            batch_texts, padding=True, truncation=True, max_length=128, return_tensors='pt'\n",
        "        ).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            output = bert_model(**encoded)\n",
        "            cls_emb = output.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            embeddings.append(cls_emb)\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "# Extract Features\n",
        "text_embeddings = extract_bert_embeddings(df_final['text_'].astype(str).tolist())\n",
        "X_hybrid = np.hstack((text_embeddings, structured_features))\n",
        "y_hybrid = df_final['target'].values\n",
        "\n",
        "# --- THE FIX IS HERE ---\n",
        "# We must unpack 8 values (Train/Test for all 4 inputs)\n",
        "X_train, X_test, y_train, y_test, text_train, text_test_raw, meta_train, meta_test_raw = train_test_split(\n",
        "    X_hybrid,\n",
        "    y_hybrid,\n",
        "    df_final['text_'],\n",
        "    structured_features,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train XGBoost\n",
        "print(\"Training XGBoost...\")\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=150, max_depth=6, learning_rate=0.05, n_jobs=-1)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "print(\"Trained.\")\n",
        "\n",
        "# ==========================================\n",
        "# [CELL 6] PHASE 5: EVALUATION\n",
        "# ==========================================\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Original', 'Fake']))\n",
        "\n",
        "# ==========================================\n",
        "# [CELL 7] PHASE 6: EXPLAINABILITY (LIME & SHAP TEXT)\n",
        "# ==========================================\n",
        "print(\"\\n--- PHASE 6: Explainability (Text-Level) ---\")\n",
        "\n",
        "# 1. DEFINE THE WRAPPER FUNCTION\n",
        "# This is the magic bridge. It takes raw text, adds the *fixed* metadata for the review we are studying,\n",
        "# runs BERT, and feeds it to XGBoost.\n",
        "class HybridPredictor:\n",
        "    def __init__(self, metadata_row):\n",
        "        self.metadata_row = metadata_row\n",
        "\n",
        "    def predict_proba(self, texts):\n",
        "        # A. Get BERT embeddings for the perturbed texts\n",
        "        # (We assume texts is a list of strings)\n",
        "        embs = extract_bert_embeddings(texts, batch_size=16)\n",
        "\n",
        "        # B. Repeat the static metadata to match the number of texts\n",
        "        # Shape: (N_texts, N_meta_features)\n",
        "        meta_batch = np.tile(self.metadata_row, (len(texts), 1))\n",
        "\n",
        "        # C. Fuse\n",
        "        combined = np.hstack((embs, meta_batch))\n",
        "\n",
        "        # D. Predict\n",
        "        return xgb_model.predict_proba(combined)\n",
        "\n",
        "# Pick a review to explain (e.g., Index 10)\n",
        "idx_to_explain = 10\n",
        "review_text = text_test_raw.iloc[idx_to_explain]\n",
        "review_meta = meta_test_raw[idx_to_explain]\n",
        "true_label = \"Fake (CG)\" if y_test[idx_to_explain]==1 else \"Original\"\n",
        "\n",
        "print(f\"Explaining Review #{idx_to_explain}\")\n",
        "print(f\"True Label: {true_label}\")\n",
        "print(f\"Text Snippet: {review_text[:100]}...\")\n",
        "\n",
        "# --- PART A: LIME (Local Interpretable Model-agnostic Explanations) ---\n",
        "print(\"\\n[A] Running LIME...\")\n",
        "predictor_instance = HybridPredictor(review_meta)\n",
        "lime_explainer = LimeTextExplainer(class_names=['Original', 'Fake'])\n",
        "\n",
        "# Run LIME (This takes a few seconds as it perturbs the text)\n",
        "exp = lime_explainer.explain_instance(\n",
        "    review_text,\n",
        "    predictor_instance.predict_proba,\n",
        "    num_features=10\n",
        ")\n",
        "\n",
        "# Show LIME Result (List of weighted words)\n",
        "print(\"LIME Weights (Positive = Fake, Negative = Original):\")\n",
        "print(exp.as_list())\n",
        "# To visualize in notebook: exp.show_in_notebook(text=True)\n",
        "\n",
        "# --- PART B: SHAP (Text Plot) ---\n",
        "# Instead of abstract embedding numbers, we use the Text masker to see WORDS.\n",
        "print(\"\\n[B] Running SHAP (Text)...\")\n",
        "\n",
        "# We create a generic wrapper for SHAP\n",
        "# Note: SHAP Text explainer is slower than TreeExplainer, so we run it on just 1-2 examples.\n",
        "def shap_predictor(texts):\n",
        "    # Wrapper that handles numpy arrays of strings\n",
        "    if isinstance(texts, np.ndarray):\n",
        "        texts = texts.tolist()\n",
        "\n",
        "    # We use the SAME metadata as above for simplicity (Local Explanation)\n",
        "    # In a perfect world, we'd map every text to its own metadata, but for\n",
        "    # text-importance analysis, holding metadata constant is standard.\n",
        "    predictor = HybridPredictor(review_meta)\n",
        "    return predictor.predict_proba(texts)\n",
        "\n",
        "# Create the Explainer\n",
        "# We use a Masker that understands English text (via the BERT tokenizer)\n",
        "masker = shap.maskers.Text(tokenizer)\n",
        "explainer = shap.Explainer(shap_predictor, masker)\n",
        "\n",
        "# Explain the single review\n",
        "shap_values = explainer([review_text])\n",
        "\n",
        "# Visualize\n",
        "print(\"SHAP Text Plot generated (Red=Fake, Blue=Original).\")\n",
        "# In Jupyter/Colab, this line renders the interactive plot:\n",
        "shap.plots.text(shap_values)\n",
        "\n",
        "# ==========================================\n",
        "# [CELL 8] PHASE 7: GLOBAL METADATA IMPORTANCE\n",
        "# ==========================================\n",
        "print(\"\\n--- PHASE 7: Global Metadata Importance ---\")\n",
        "# Since BERT embeddings are abstract, the best \"Global\" chart is\n",
        "# showing how much the METADATA matters compared to the text.\n",
        "\n",
        "# 1. Get raw importance from XGBoost\n",
        "importance = xgb_model.feature_importances_\n",
        "\n",
        "# 2. Separate Text vs Metadata\n",
        "# First 768 features are BERT, rest are Metadata\n",
        "bert_importance = np.sum(importance[:768])\n",
        "meta_importances = importance[768:]\n",
        "meta_names = feature_names\n",
        "\n",
        "# 3. Plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "# We create a list: [BERT_Aggregate] + [Metadata_Features]\n",
        "plot_names = ['BERT (Text Aggregate)'] + meta_names\n",
        "plot_values = [bert_importance] + list(meta_importances)\n",
        "\n",
        "# Sort for nicer plotting\n",
        "sorted_idx = np.argsort(plot_values)\n",
        "plt.barh(np.array(plot_names)[sorted_idx], np.array(plot_values)[sorted_idx], color='teal')\n",
        "plt.title(\"Global Feature Importance: Text vs Metadata\")\n",
        "plt.xlabel(\"Relative Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZZj9XONBWNLr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}